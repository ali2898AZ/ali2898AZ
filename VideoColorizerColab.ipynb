{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ali2898AZ/ali2898AZ/blob/main/VideoColorizerColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UcCeCbgqxpj"
      },
      "source": [
        "### **<font color='blue'> Video Colorizer </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "663IVxfrpIAb"
      },
      "source": [
        "#◢ DeOldify - Colorize your own videos!\n",
        "\n",
        "\n",
        "_FYI: This notebook is intended as a tool to colorize gifs and short videos, if you are trying to convert longer video you may hit the limit on processing space. Running the Jupyter notebook on your own machine is recommended (and faster) for larger video sizes._\n",
        "\n",
        "####**Credits:**\n",
        "\n",
        "Big special thanks to:\n",
        "\n",
        "Robert Bell for all his work on the video Colab notebook, and paving the way to video in DeOldify!\n",
        "\n",
        "Dana Kelley for doing things, breaking stuff & having an opinion on everything."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjPqTBNoohK9"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "#◢ Verify Correct Runtime Settings\n",
        "\n",
        "**<font color='#FF000'> IMPORTANT </font>**\n",
        "\n",
        "In the \"Runtime\" menu for the notebook window, select \"Change runtime type.\" Ensure that the following are selected:\n",
        "* Runtime Type = Python 3\n",
        "* Hardware Accelerator = GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaEJBGDlptEo"
      },
      "source": [
        "#◢ Git clone and install DeOldify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-T-svuHytJ-8",
        "outputId": "27d84de8-c6ad-422c-d340-c6f62621ea54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeOldify'...\n",
            "remote: Enumerating objects: 2620, done.\u001b[K\n",
            "remote: Counting objects: 100% (106/106), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 2620 (delta 64), reused 46 (delta 46), pack-reused 2514 (from 3)\u001b[K\n",
            "Receiving objects: 100% (2620/2620), 69.73 MiB | 21.07 MiB/s, done.\n",
            "Resolving deltas: 100% (1174/1174), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/jantic/DeOldify.git DeOldify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1jxdFFI1qxqD",
        "outputId": "58dec039-f3b2-4c16-968d-beacea749e86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DeOldify\n"
          ]
        }
      ],
      "source": [
        "cd DeOldify"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDFjbNxaadNJ"
      },
      "source": [
        "#◢ Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "00_GcC_trpdE"
      },
      "outputs": [],
      "source": [
        "#NOTE:  This must be the first call in order to work properly!\n",
        "from deoldify import device\n",
        "from deoldify.device_id import DeviceId\n",
        "#choices:  CPU, GPU0...GPU7\n",
        "device.set(device=DeviceId.GPU0)\n",
        "\n",
        "import torch\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print('GPU not available.')\n",
        "\n",
        "from os import path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Lsx7xCXNSVt6",
        "outputId": "d903d6e5-7057-422b-83bc-c4b564ac2b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fastai==1.0.60 (from -r requirements-colab.txt (line 1))\n",
            "  Downloading fastai-1.0.60-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting tensorboardX>=1.6 (from -r requirements-colab.txt (line 2))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting ffmpeg-python (from -r requirements-colab.txt (line 3))\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting yt-dlp (from -r requirements-colab.txt (line 4))\n",
            "  Downloading yt_dlp-2025.4.30-py3-none-any.whl.metadata (173 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.3/173.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=4.2.0.32 in /usr/local/lib/python3.11/dist-packages (from -r requirements-colab.txt (line 5)) (4.11.0.86)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements-colab.txt (line 6)) (11.2.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from -r requirements-colab.txt (line 7)) (6.4.2)\n",
            "Collecting imgaug==0.2.6 (from -r requirements-colab.txt (line 8))\n",
            "  Downloading imgaug-0.2.6.tar.gz (631 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m631.4/631.4 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (4.13.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.10.2)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.0.2)\n",
            "Collecting nvidia-ml-py3 (from fastai==1.0.60->-r requirements-colab.txt (line 1))\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.8.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from imgaug==0.2.6->-r requirements-colab.txt (line 8)) (0.25.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from imgaug==0.2.6->-r requirements-colab.txt (line 8)) (1.17.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=1.6->-r requirements-colab.txt (line 2)) (5.29.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from ffmpeg-python->-r requirements-colab.txt (line 3)) (1.0.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6->-r requirements-colab.txt (line 8)) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6->-r requirements-colab.txt (line 8)) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6->-r requirements-colab.txt (line 8)) (2025.5.10)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.11.0->imgaug==0.2.6->-r requirements-colab.txt (line 8)) (0.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (4.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.60->-r requirements-colab.txt (line 1)) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2025.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (8.2.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (2.19.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy>=2.0.18->fastai==1.0.60->-r requirements-colab.txt (line 1)) (0.1.2)\n",
            "Downloading fastai-1.0.60-py3-none-any.whl (237 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.3/237.3 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading yt_dlp-2025.4.30-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: imgaug, nvidia-ml-py3\n",
            "  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imgaug: filename=imgaug-0.2.6-py3-none-any.whl size=654003 sha256=6a0641557759a6530a2a9fd1de438397ff05f85b128d8158c6625ea31e630784\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/82/dc/ed45b805daac0354f5e10a19b3fc2ca22bcac4429b010a3088\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=b22483be6ef592dafb387076202e6a9660c7cd810f423a8a5e3887c533723390\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\n",
            "Successfully built imgaug nvidia-ml-py3\n",
            "Installing collected packages: nvidia-ml-py3, yt-dlp, tensorboardX, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ffmpeg-python, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, imgaug, fastai\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: fastai\n",
            "    Found existing installation: fastai 2.7.19\n",
            "    Uninstalling fastai-2.7.19:\n",
            "      Successfully uninstalled fastai-2.7.19\n",
            "Successfully installed fastai-1.0.60 ffmpeg-python-0.2.0 imgaug-0.2.6 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py3-7.352.0 nvidia-nvjitlink-cu12-12.4.127 tensorboardX-2.6.2.2 yt-dlp-2025.4.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pynvml"
                ]
              },
              "id": "03d7109c91a14f42b05ac2023eb28472"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install -r requirements-colab.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsJa69CMwj3l",
        "outputId": "0047ae09-4b74-42e7-f0b3-1ec11e543460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumExpr defaulting to 2 threads.\n"
          ]
        }
      ],
      "source": [
        "import fastai\n",
        "from deoldify.visualize import *\n",
        "from pathlib import Path\n",
        "torch.backends.cudnn.benchmark=True\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*?Your .*? set is empty.*?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rWdzbbUIqxqV",
        "outputId": "278bbe02-e67e-4a87-b3f0-22378ca24969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘models’: File exists\n",
            "--2025-05-21 07:09:53--  https://data.deepai.org/deoldify/ColorizeVideo_gen.pth\n",
            "Resolving data.deepai.org (data.deepai.org)... 169.150.249.167, 2400:52e0:1a01::852:1\n",
            "Connecting to data.deepai.org (data.deepai.org)|169.150.249.167|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 874066230 (834M) [application/octet-stream]\n",
            "Saving to: ‘./models/ColorizeVideo_gen.pth’\n",
            "\n",
            "./models/ColorizeVi 100%[===================>] 833.57M  4.90MB/s    in 2m 50s  \n",
            "\n",
            "2025-05-21 07:12:43 (4.89 MB/s) - ‘./models/ColorizeVideo_gen.pth’ saved [874066230/874066230]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir 'models'\n",
        "!wget https://data.deepai.org/deoldify/ColorizeVideo_gen.pth -O ./models/ColorizeVideo_gen.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "tzHVnegp21hC",
        "outputId": "56e292c6-d146-4b13-e9ab-9b732608af95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n",
            "100%|██████████| 171M/171M [00:01<00:00, 175MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL functools.partial was not an allowed global by default. Please use `torch.serialization.add_safe_globals([partial])` or the `torch.serialization.safe_globals([partial])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-81c07a854ecc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_video_colorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/DeOldify/deoldify/visualize.py\u001b[0m in \u001b[0;36mget_video_colorizer\u001b[0;34m(render_factor)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_video_colorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mVideoColorizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_stable_video_colorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DeOldify/deoldify/visualize.py\u001b[0m in \u001b[0;36mget_stable_video_colorizer\u001b[0;34m(root_folder, weights_name, results_dir, render_factor)\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0mrender_factor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m ) -> VideoColorizer:\n\u001b[0;32m--> 432\u001b[0;31m     \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_inference_wide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroot_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     \u001b[0mfiltr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMasterFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mColorizerFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrender_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0mvis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelImageVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DeOldify/deoldify/generators.py\u001b[0m in \u001b[0;36mgen_inference_wide\u001b[0;34m(root_folder, weights_name, nf_factor, arch)\u001b[0m\n\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     18\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroot_folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DeOldify/fastai/basic_train.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, file, device, strict, with_opt, purge, remove_module)\u001b[0m\n\u001b[1;32m    265\u001b[0m              with_opt:bool=None, purge:bool=True, remove_module:bool=False):\n\u001b[1;32m    266\u001b[0m         \u001b[0;34m\"Load model and optimizer state (if `with_opt`) `file` from `self.model_dir` using `device`. `file` can be file-like (file or buffer)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mpurge\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpurge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear_opt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DeOldify/fastai/basic_train.py\u001b[0m in \u001b[0;36mpurge\u001b[0;34m(self, clear_opt)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattrs_del\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1468\u001b[0m                         )\n\u001b[1;32m   1469\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1470\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1471\u001b[0m                 return _load(\n\u001b[1;32m   1472\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL functools.partial was not an allowed global by default. Please use `torch.serialization.add_safe_globals([partial])` or the `torch.serialization.safe_globals([partial])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ],
      "source": [
        "colorizer = get_video_colorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2D0OhgZqxqb"
      },
      "source": [
        "#◢ Instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRwg2keaqxqe"
      },
      "source": [
        "### source_url\n",
        "Type in a url hosting a video from YouTube, Imgur, Twitter, Reddit, Vimeo, etc.  Many sources work!  GIFs also work.  Full list here: https://ytdl-org.github.io/youtube-dl/supportedsites.html NOTE: If you want to use your own video, upload it first to a site like YouTube.\n",
        "\n",
        "### render_factor\n",
        "The default value of 21 has been carefully chosen and should work -ok- for most scenarios (but probably won't be the -best-). This determines resolution at which the color portion of the video is rendered. Lower resolution will render faster, and colors also tend to look more vibrant. Older and lower quality film in particular will generally benefit by lowering the render factor. Higher render factors are often better for higher quality videos and inconsistencies (flashy render) will generally be reduced, but the colors may get slightly washed out.\n",
        "\n",
        "### watermarked\n",
        "Selected by default, this places a watermark icon of a palette at the bottom left corner of the image.  This is intended to be a standard way to convey to others viewing the image that it is colorized by AI. We want to help promote this as a standard, especially as the technology continues to improve and the distinction between real and fake becomes harder to discern. This palette watermark practice was initiated and lead by the company MyHeritage in the MyHeritage In Color feature (which uses a newer version of DeOldify than what you're using here).\n",
        "\n",
        "### How to Download a Copy\n",
        "Simply right click on the displayed video and click \"Save video as...\"!\n",
        "\n",
        "## Pro Tips\n",
        "1. If a video takes a long time to render and you're wondering how well the frames will actually be colorized, you can preview how well the frames will be rendered at each render_factor by using the code at the bottom. Just stop the video rendering by hitting the stop button on the cell, then run that bottom cell under \"See how well render_factor values perform on a frame here\". It's not perfect and you may still need to experiment a bit especially when it comes to figuring out how to reduce frame inconsistency.  But it'll go a long way in narrowing down what actually works.\n",
        "2. If videos are taking way too much time for your liking, running the Jupyter notebook VideoColorizer.ipynb on your own machine (with DeOldify installed) will generally be much faster (as long as you have the hardware for it).   \n",
        "3. Longer videos (running multiple minutes) are going to have a rough time on Colabs. You'll be much better off using a local install of DeOldify instead in this case.\n",
        "\n",
        "## Troubleshooting\n",
        "The video player may wind up not showing up, in which case- make sure to wait for the Jupyter cell to complete processing first (the play button will stop spinning).  Then follow these alternative download instructions\n",
        "\n",
        "1. In the menu to the left, click Files\n",
        "2. If you don't see the 'DeOldify' folder, click \"Refresh\"\n",
        "3. By default, rendered video will be in /DeOldify/video/result/\n",
        "\n",
        "If a video you downloaded doesn't play, it's probably because the cell didn't complete processing and the video is in a half-finished state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUQrbSYipiJn"
      },
      "source": [
        "#◢ Colorize!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TZfEPCdNqxqh",
        "outputId": "5ad090c9-be9b-43f9-e4ad-9bd542febb7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'colorizer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e091d3175d8e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource_url\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msource_url\u001b[0m \u001b[0;34m!=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mvideo_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorize_from_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'video.mp4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatermarked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwatermarked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mshow_video_in_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'colorizer' is not defined"
          ]
        }
      ],
      "source": [
        "source_url = 'https://youtube.com/shorts/9MzUGcddUrU?si=wWyWeveiXXyyMMML' #@param {type:\"string\"}\n",
        "render_factor = 21  #@param {type: \"slider\", min: 5, max: 40}\n",
        "watermarked = True #@param {type:\"boolean\"}\n",
        "\n",
        "if source_url is not None and source_url !='':\n",
        "    video_path = colorizer.colorize_from_url(source_url, 'video.mp4', render_factor, watermarked=watermarked)\n",
        "    show_video_in_notebook(video_path)\n",
        "else:\n",
        "    print('Provide a video url and try again.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J4OfYC8qxqj"
      },
      "source": [
        "## See how well render_factor values perform on a frame here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgoyD2foqxqm"
      },
      "outputs": [],
      "source": [
        "for i in range(10,40,2):\n",
        "    colorizer.vis.plot_transformed_image('video/bwframes/video/00001.jpg', render_factor=i, display_render_factor=True, figsize=(8,8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7Ycv_Y9xAHp"
      },
      "source": [
        "---\n",
        "#⚙ Recommended video and gif sources\n",
        "* [/r/Nickelodeons/](https://www.reddit.com/r/Nickelodeons/)\n",
        "* [r/silentmoviegifs](https://www.reddit.com/r/silentmoviegifs/)\n",
        "* https://twitter.com/silentmoviegifs"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "VideoColorizerColab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}